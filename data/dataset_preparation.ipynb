{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f336c95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1af98dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CONFIGURATION ---\n",
    "# Dataset 1 (Strokes)\n",
    "STROKE_DATASET_PATH = \"../content/Brain_Stroke_MRI/Dataset_MRI_Folder\" \n",
    "\n",
    "# Dataset 2 (Tumors) usually unzips to 'Training' and 'Testing' folders\n",
    "# pointing to the \"Training\" dir to get the most images\n",
    "TUMOR_DATASET_PATH = \"../content/Brain_Tumor_Classification/Training\" \n",
    "\n",
    "OUTPUT_DIR = \"../content/dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c227634b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_structure():\n",
    "    classes = [\"Hemorrhagic\", \"Ischemic\", \"Tumor\"]\n",
    "    for c in classes:\n",
    "        os.makedirs(os.path.join(OUTPUT_DIR, c), exist_ok=True)\n",
    "    print(f\"Created directories in {OUTPUT_DIR}\")\n",
    "\n",
    "def copy_images_recursive(src_dir, dst_class_name, limit=None):\n",
    "    \"\"\"Recursively copies all images from source directory and subdirectories.\"\"\"\n",
    "    if not os.path.exists(src_dir):\n",
    "        print(f\"WARNING: Source directory not found: {src_dir}\")\n",
    "        return\n",
    "\n",
    "    dst_dir = os.path.join(OUTPUT_DIR, dst_class_name)\n",
    "    \n",
    "    # Recursively find all image files\n",
    "    image_files = []\n",
    "    for root, dirs, files in os.walk(src_dir):\n",
    "        for f in files:\n",
    "            if f.lower().endswith(('.jpg', '.jpeg', '.png', '.dcm', '.nii', '.nii.gz')):\n",
    "                image_files.append(os.path.join(root, f))\n",
    "    \n",
    "    # Optional: limit number of images to balance the dataset if needed\n",
    "    if limit:\n",
    "        image_files = image_files[:limit]\n",
    "        \n",
    "    print(f\"Copying {len(image_files)} images from {src_dir} to {dst_class_name}...\")\n",
    "    \n",
    "    for img_path in tqdm(image_files):\n",
    "        # Create unique filename to avoid overwrites from different subdirs\n",
    "        rel_path = os.path.relpath(img_path, src_dir)\n",
    "        filename = rel_path.replace(os.sep, '_')\n",
    "        # Replace spaces and other problematic characters\n",
    "        filename = filename.replace(' ', '_')\n",
    "        shutil.copy(img_path, os.path.join(dst_dir, filename))\n",
    "\n",
    "def copy_images(src_dir, dst_class_name, limit=None):\n",
    "    \"\"\"Copies images from source to the destination class folder (non-recursive).\"\"\"\n",
    "    if not os.path.exists(src_dir):\n",
    "        print(f\"WARNING: Source directory not found: {src_dir}\")\n",
    "        return\n",
    "\n",
    "    dst_dir = os.path.join(OUTPUT_DIR, dst_class_name)\n",
    "    files = [f for f in os.listdir(src_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    \n",
    "    # Optional: limit number of images to balance the dataset if needed\n",
    "    if limit:\n",
    "        files = files[:limit]\n",
    "        \n",
    "    print(f\"Copying {len(files)} images from {src_dir} to {dst_class_name}...\")\n",
    "    \n",
    "    for f in tqdm(files):\n",
    "        shutil.copy(os.path.join(src_dir, f), os.path.join(dst_dir, f))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38ae87a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created directories in ../content/dataset\n",
      "Copying 186 images from ../content/Brain_Stroke_MRI/Dataset_MRI_Folder\\Haemorrhagic to Hemorrhagic...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/186 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 186/186 [00:01<00:00, 103.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying 30 images from ../content/Brain_Stroke_MRI/Dataset_MRI_Folder\\Ischemic to Ischemic...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:00<00:00, 89.79it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying 822 images from ../content/Brain_Tumor_Classification/Training\\meningioma_tumor to Tumor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 822/822 [00:07<00:00, 113.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset generation complete!\n",
      "Please check the 'content/dataset' folder.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Setup\n",
    "create_dataset_structure()\n",
    "\n",
    "# 2. Process Strokes (Dataset 1) - Recursively copy from all subdirectories\n",
    "# Note: Check your unzipped folder names carefully! \n",
    "# They are often named 'Haemorrhagic' and 'Ischemic' inside the dataset.\n",
    "copy_images_recursive(os.path.join(STROKE_DATASET_PATH, \"Haemorrhagic\"), \"Hemorrhagic\")\n",
    "copy_images_recursive(os.path.join(STROKE_DATASET_PATH, \"Ischemic\"), \"Ischemic\")\n",
    "\n",
    "# 3. Process Tumors (Dataset 2)\n",
    "# We merge Glioma, Meningioma, and Pituitary into one 'Tumor' class\n",
    "# copy_images(os.path.join(TUMOR_DATASET_PATH, \"glioma_tumor\"), \"Tumor\")\n",
    "copy_images(os.path.join(TUMOR_DATASET_PATH, \"meningioma_tumor\"), \"Tumor\")\n",
    "# copy_images(os.path.join(TUMOR_DATASET_PATH, \"pituitary_tumor\"), \"Tumor\")\n",
    "\n",
    "print(\"\\nDataset generation complete!\")\n",
    "print(\"Please check the 'content/dataset' folder.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3e26065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting: ../content\\Brain_Stroke_MRI\n",
      "Deleting: ../content\\Brain_Tumor_Classification\n",
      "Cleanup complete! Only 'dataset' folder remains.\n"
     ]
    }
   ],
   "source": [
    "# Delete all folders in content except 'dataset'\n",
    "content_dir = \"../content\"\n",
    "for item in os.listdir(content_dir):\n",
    "    item_path = os.path.join(content_dir, item)\n",
    "    if os.path.isdir(item_path) and item != \"dataset\":\n",
    "        print(f\"Deleting: {item_path}\")\n",
    "        shutil.rmtree(item_path)\n",
    "\n",
    "print(\"Cleanup complete! Only 'dataset' folder remains.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
